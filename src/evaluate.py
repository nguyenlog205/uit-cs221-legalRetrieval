import pandas as pd
import re
import os
import argparse
import sys
from datasets import Dataset
import warnings

# Táº¯t warning
warnings.filterwarnings("ignore")

try:
    # Import Ragas metrics
    from ragas.metrics import (
        faithfulness,
        answer_relevancy,
        context_precision,
        context_recall,
        answer_correctness
    )
    from ragas import evaluate, RunConfig
    
    # --- THAY Äá»”I: DÃ¹ng Google Gemini thay vÃ¬ Groq ---
    from langchain_google_genai import ChatGoogleGenerativeAI
    
    # Váº«n giá»¯ BGE-M3 Ä‘á»ƒ lÃ m Embeddings (Retrieval cháº¥m Ä‘iá»ƒm)
    from langchain_community.embeddings import HuggingFaceEmbeddings

except ImportError as e:
    print(f"Lá»—i thiáº¿u thÆ° viá»‡n: {e}")
    print("ğŸ‘‰ HÃ£y cháº¡y: pip install langchain-google-genai")
    sys.exit(1)

class RAGEvaluator:
    # Äá»•i tÃªn tham sá»‘ key cho rÃµ rÃ ng, máº·c Ä‘á»‹nh model lÃ  gemini-1.5-flash (Ngon-Bá»•-Ráº»)
    def __init__(self, google_api_key: str = None, llm_model: str = "gemini-3-flash-preview"):
        self.google_api_key = google_api_key
        self.llm_model = llm_model
        
        print("â³ Äang khá»Ÿi táº¡o Embeddings (BGE-M3)...")
        # Embeddings váº«n cháº¡y local báº±ng GPU cá»§a Ã´ng cho nhanh
        self.embeddings = HuggingFaceEmbeddings(
            model_name="BAAI/bge-m3",
            model_kwargs={'device': 'cuda', 'trust_remote_code': True}, 
            encode_kwargs={'normalize_embeddings': True}
        )

    def _prepare_ragas_data(self, df: pd.DataFrame) -> Dataset:
        eval_df = df.copy()
        
        def clean_context(ctx):
            if not isinstance(ctx, str): return []
            pattern = r"page_content=['\"](.*?)['\"](?:,|$|\))"
            matches = re.findall(pattern, ctx, re.DOTALL)
            return matches if matches else [ctx]

        if 'context' in eval_df.columns:
            eval_df['contexts'] = eval_df['context'].apply(clean_context)
        
        rename_map = {
            'question': 'question', 
            'model_output': 'answer', 
            'answer': 'ground_truth'
        }
        actual_map = {k: v for k, v in rename_map.items() if k in eval_df.columns}
        eval_df = eval_df.rename(columns=actual_map)
        
        req = [c for c in ['question', 'answer', 'contexts', 'ground_truth'] if c in eval_df.columns]
        return Dataset.from_pandas(eval_df.dropna(subset=req))

    def evaluate_ragas(self, df: pd.DataFrame, api_key: str = None) -> pd.DataFrame:
        final_key = api_key if api_key else self.google_api_key
        if not final_key: raise ValueError("Cáº§n Google API Key!")

        # --- Cáº¤U HÃŒNH GOOGLE GEMINI ---
        llm = ChatGoogleGenerativeAI(
            google_api_key=final_key,
            model=self.llm_model,
            temperature=0, # Nhiá»‡t Ä‘á»™ 0 Ä‘á»ƒ cháº¥m Ä‘iá»ƒm khÃ¡ch quan nháº¥t
            convert_system_message_to_human=True # Fix lá»—i format tin nháº¯n cÅ©
        )
        
        dataset = self._prepare_ragas_data(df)
        
        metrics = [context_precision, context_recall, faithfulness, answer_relevancy, answer_correctness]
        
        # Cáº¥u hÃ¬nh cháº¡y: Google cho phÃ©p 15 requests/phÃºt (RPM) á»Ÿ gÃ³i Free
        # Äá»ƒ an toÃ n tuyá»‡t Ä‘á»‘i, ta cháº¡y max_workers=1 hoáº·c 2.
        # Náº¿u Ã´ng muá»‘n nhanh hÆ¡n xÃ­u cÃ³ thá»ƒ chá»‰nh lÃªn 2, nhÆ°ng 1 lÃ  an toÃ n nháº¥t.
        run_config = RunConfig(
            max_workers=1,  
            timeout=120,
            max_retries=10,
            max_wait=30
        )

        print(f"ğŸš€ Äang cháº¥m Ä‘iá»ƒm báº±ng Ragas (Model: {self.llm_model})...")
        print("âš ï¸ Äang dÃ¹ng Google Gemini. Cháº¿ Ä‘á»™ cháº¡y tuáº§n tá»± Ä‘á»ƒ nÃ© Rate Limit.")
        
        results = evaluate(
            dataset=dataset, 
            metrics=metrics, 
            llm=llm, 
            embeddings=self.embeddings,
            run_config=run_config
        )
        return results.to_pandas()

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--input', type=str, required=True)
    
    # Äá»•i tÃªn tham sá»‘ CLI cho khá»›p context
    parser.add_argument('--api_key', type=str, required=True, help="Google AI Studio API Key")
    
    parser.add_argument('--mode', type=str, default="ragas") 
    parser.add_argument('--model', type=str, default="gemini-3-flash-preview")
    args = parser.parse_args()

    filename = os.path.basename(args.input)
    out_dir = "data/evaluation"
    os.makedirs(out_dir, exist_ok=True)
    out_path = os.path.join(out_dir, filename)

    print(f"ğŸ“‚ Äá»c file: {args.input}")
    df = pd.read_csv(args.input)

    try:
        evaluator = RAGEvaluator(llm_model=args.model)
        
        print("--- Báº¯t Ä‘áº§u cháº¿ Ä‘á»™ Ragas (Gemini Powered) ---")
        result_df = evaluator.evaluate_ragas(df, api_key=args.api_key)
            
        result_df.to_csv(out_path, index=False)
        print(f"âœ… Xong! Káº¿t quáº£ lÆ°u táº¡i: {out_path}")

    except Exception as e:
        print(f"\nâŒ Lá»–I: {e}")

if __name__ == "__main__":
    main()