import os
import uvicorn
import logging
from contextlib import asynccontextmanager
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import Optional, List

# --- Import cÃ¡c Module Agents ---
# Giáº£ sá»­ IntentClassifier vÃ  GeneralGenerator váº«n dÃ¹ng Groq (hoáº·c báº¡n cÃ³ thá»ƒ sá»­a sau)
from src.agents.intent_classifier import IntentClassifier 
from src.agents.database_retriever import DatabaseRetriever
from src.agents.specialized_generator import SpecificGenerator
from src.agents.general_generator import GeneralGenerator
from src.utils import load_env

# --- Cáº¥u hÃ¬nh Logging ---
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# --- Data Models (Pydantic) ---
class ChatRequest(BaseModel):
    query: str
    session_id: Optional[str] = None

class ChatResponse(BaseModel):
    response: str
    intent: str
    source_documents: Optional[List[str]] = None

# --- Global State ---
agents = {}

# --- Cáº¥u hÃ¬nh URL ---
# URL cá»§a Local Model Server (Gemma/Llama mÃ  báº¡n Ä‘ang cháº¡y á»Ÿ cá»­a sá»• kia)
LOCAL_LLM_URL = "http://localhost:8000/chat" 

# --- Lifespan Manager ---
@asynccontextmanager
async def lifespan(app: FastAPI):
    logger.info("--- KHá»I Äá»˜NG Há»† THá»NG RAG ---")
    
    # 1. Load API Key (Váº«n cáº§n cho Intent Classifier hoáº·c General Gen náº¿u chÃºng dÃ¹ng Groq)
    api_key = load_env("GROQ_API_KEY") 
    
    # Náº¿u IntentClassifier cÅ©ng chuyá»ƒn sang Local thÃ¬ khÃ´ng cáº§n check ká»¹ cÃ¡i nÃ y, 
    # nhÆ°ng táº¡m thá»i giá»¯ nguyÃªn logic cÅ© cho an toÃ n.
    if not api_key:
        logger.warning("âš ï¸ Warning: KhÃ´ng tháº¥y GROQ_API_KEY. CÃ¡c module dÃ¹ng Groq sáº½ lá»—i.")

    try:
        # 2. Khá»Ÿi táº¡o Intent Classifier
        logger.info("Initializing Intent Classifier...")
        agents["classifier"] = IntentClassifier(api_key=api_key)

        # 3. Khá»Ÿi táº¡o General Generator (Chat xÃ£ giao)
        logger.info("Initializing General Generator...")
        agents["general_gen"] = GeneralGenerator(api_key=api_key)

        # 4. Khá»Ÿi táº¡o Specialized Generator (UPDATE: DÃ¹ng Local API)
        logger.info(f"Initializing Specialized Generator pointing to {LOCAL_LLM_URL}...")
        agents["specific_gen"] = SpecificGenerator(
            api_key="unused",       # Giá»¯ tham sá»‘ nÃ y Ä‘á»ƒ khÃ´ng lá»—i code cÅ© (náº¿u class yÃªu cáº§u)
            api_url=LOCAL_LLM_URL,  # Trá» vÃ o server Gemma
            max_output_tokens=512
        )

        # 5. Khá»Ÿi táº¡o Database Retriever
        config_path = "configs/indexing_pipeline.yml" 
        if os.path.exists(config_path):
            logger.info(f"Initializing Database Retriever from {config_path}...")
            agents["retriever"] = DatabaseRetriever.from_config(config_path=config_path)
        else:
            logger.warning(f"Warning: KhÃ´ng tÃ¬m tháº¥y {config_path}. Cháº¿ Ä‘á»™ Specific cÃ³ thá»ƒ bá»‹ lá»—i.")
            agents["retriever"] = None
            
        logger.info("--- Há»† THá»NG ÄÃƒ Sáº´N SÃ€NG ---")
        
    except Exception as e:
        logger.error(f"Lá»—i khá»Ÿi táº¡o há»‡ thá»‘ng: {e}")
        raise e

    yield # Server báº¯t Ä‘áº§u nháº­n request

    logger.info("Shutting down system...")
    agents.clear()

# --- Khá»Ÿi táº¡o App FastAPI ---
app = FastAPI(title="Vietnam Public Health RAG API", lifespan=lifespan)

# --- API Endpoints ---

@app.get("/health")
async def health_check():
    """Kiá»ƒm tra tráº¡ng thÃ¡i server"""
    return {
        "status": "ok", 
        "components": list(agents.keys()),
        "local_llm_target": LOCAL_LLM_URL
    }

@app.post("/chat", response_model=ChatResponse)
async def chat_endpoint(request: ChatRequest):
    query = request.query.strip()
    if not query:
        raise HTTPException(status_code=400, detail="CÃ¢u há»i khÃ´ng Ä‘Æ°á»£c Ä‘á»ƒ trá»‘ng.")

    # 1. PhÃ¢n loáº¡i Ã½ Ä‘á»‹nh
    try:
        intent = await agents["classifier"].classify(query)
    except Exception as e:
        logger.error(f"Classifier Error: {e}")
        intent = "specific" # Fallback vá» specific náº¿u classifier lá»—i
    
    logger.info(f"Input: '{query}' | Intent: {intent}")

    # 2. NHÃNH 1: GENERAL (XÃ£ giao)
    if intent == "general":
        try:
            response_text = agents["general_gen"].generate_general(query)
            return ChatResponse(response=response_text, intent="general", source_documents=[])
        except Exception:
            intent = "specific" # Náº¿u lá»—i thÃ¬ thá»­ Ä‘áº©y sang RAG luÃ´n

    # 3. NHÃNH 2: SPECIFIC (RAG vá»›i Local LLM)
    if intent == "specific":
        retriever = agents.get("retriever")
        
        if not retriever:
            return ChatResponse(
                response="Há»‡ thá»‘ng cÆ¡ sá»Ÿ dá»¯ liá»‡u chÆ°a sáºµn sÃ ng.", 
                intent="error"
            )

        # 3a. Retrieve
        retrieved_docs = await retriever.retrieve(query, k=5)
        
        # 3b. Fallback náº¿u khÃ´ng cÃ³ tÃ i liá»‡u
        if not retrieved_docs:
            logger.info("No docs found -> Fallback.")
            fallback_text = agents["general_gen"].generate_fallback(query)
            return ChatResponse(
                response=fallback_text, 
                intent="specific_fallback", 
                source_documents=[]
            )

        # 3c. Generate (Gá»i sang Local Server 8000)
        answer = await agents["specific_gen"].generate_response(query, retrieved_docs)
        
        sources = [doc.metadata.get("source", "Unknown") for doc in retrieved_docs]
        
        return ChatResponse(
            response=answer,
            intent="specific",
            source_documents=list(set(sources))
        )

# --- Entry Point ---
if __name__ == "__main__":
    # QUAN TRá»ŒNG: Äá»•i port thÃ nh 8001 Ä‘á»ƒ trÃ¡nh xung Ä‘á»™t vá»›i Model Server (8000)
    print("ğŸš€ Starting RAG API Server on port 8001...")
    uvicorn.run("main_api:app", host="0.0.0.0", port=8001, reload=True)