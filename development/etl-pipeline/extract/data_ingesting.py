import os
import json
import time # <-- ThÃªm thÆ° viá»‡n time Ä‘á»ƒ táº¡o deploy_key
import pandas as pd
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException
from webdriver_manager.chrome import ChromeDriverManager

class DataIngestionTool:
    """
    Má»™t cÃ´ng cá»¥ Ä‘á»ƒ cÃ o dá»¯ liá»‡u vÄƒn báº£n phÃ¡p luáº­t tá»« trang vbpl.vn.
    """
    def __init__(self, web_link: str = 'https://vbpl.vn/pages/portal.aspx'):
        """
        Khá»Ÿi táº¡o WebDriver, tá»± Ä‘á»™ng quáº£n lÃ½ chromedriver.

        Args:
            web_link (str, optional): Link cá»§a trang web cáº§n cÃ o. Máº·c Ä‘á»‹nh lÃ  'https://vbpl.vn/pages/portal.aspx'.
        """
        self.webpage_link = web_link
        try:
            self.service = Service(ChromeDriverManager().install())
            self.driver = webdriver.Chrome(service=self.service)
            print("ğŸŸ¢ Táº¡o driver thÃ nh cÃ´ng.")
        except Exception as e:
            print(f"â­• Lá»—i khi táº¡o driver: {e}")
            self.driver = None

    def ingest_data(self, keyword: str, output_dir: str):
        """
        Táº£i vá» toÃ n bá»™ vÄƒn báº£n phÃ¡p luáº­t vÃ  metadata liÃªn quan tá»›i keyword.

        Args:
            keyword (str): Tá»« khÃ³a tÃ¬m kiáº¿m.
            output_dir (str): ThÆ° má»¥c Ä‘á»ƒ lÆ°u file JSON káº¿t quáº£.
        """
        if not self.driver:
            print("Driver chÆ°a Ä‘Æ°á»£c khá»Ÿi táº¡o. Dá»«ng thá»±c thi.")
            return

        self.driver.get(self.webpage_link)
        keyword = keyword.strip()
        all_documents = []

        print(f'\n============== Báº¯t Ä‘áº§u tÃ¬m kiáº¿m: "{keyword}" ==============')
        try:
            search_box = WebDriverWait(self.driver, 10).until(
                EC.presence_of_element_located((By.ID, "AdvanceKeyword"))
            )
            search_box.clear()
            search_box.send_keys(keyword)
            search_box.send_keys(Keys.ENTER)

            result_count_object = WebDriverWait(self.driver, 10).until(
                EC.presence_of_element_located((By.XPATH, '//span[contains(text(), "TÃ¬m tháº¥y")]/strong'))
            )
            number_of_results = int(result_count_object.text)
            print(f"ğŸ”¬ ÄÃ£ tÃ¬m tháº¥y {number_of_results} vÄƒn báº£n phÃ¡p luáº­t.")
            if number_of_results == 0:
                return # KhÃ´ng cÃ³ káº¿t quáº£, chuyá»ƒn sang keyword tiáº¿p theo
        except TimeoutException:
            print(f"â­• KhÃ´ng tÃ¬m tháº¥y káº¿t quáº£ nÃ o cho tá»« khÃ³a '{keyword}' hoáº·c trang táº£i quÃ¡ lÃ¢u.")
            return
        except Exception as e:
            print(f"â­• Lá»—i khi tÃ¬m kiáº¿m: {e}")
            return

        page_number = 1
        
        while True:
            try:
                WebDriverWait(self.driver, 10).until(
                    EC.presence_of_element_located((By.CLASS_NAME, "listLaw"))
                )
                ul_element = self.driver.find_element(By.CLASS_NAME, "listLaw")
                li_elements = ul_element.find_elements(By.TAG_NAME, "li")
                print(f"ğŸ” Äang xá»­ lÃ½ trang {page_number} vá»›i {len(li_elements)} káº¿t quáº£...")
                
                page_data = []
                for li in li_elements:
                    try:
                        a_tag = li.find_element(By.CSS_SELECTOR, "p.title > a")
                        detail_link = a_tag.get_attribute("href")
                        
                        doc_info = {
                            "TÃªn vÄƒn báº£n": a_tag.text.strip(),
                            "Link chi tiáº¿t": detail_link,
                            "MÃ´ táº£": li.find_element(By.CSS_SELECTOR, "div.des > p").text.strip(),
                            "PDF": li.find_element(By.CSS_SELECTOR, "li.source > a").get_attribute("href"),
                            "Ban hÃ nh": li.find_element(By.CSS_SELECTOR, "div.right > p.green:nth-of-type(1)").text.split(":", 1)[-1].strip(),
                            "Hiá»‡u lá»±c": li.find_element(By.CSS_SELECTOR, "div.right > p.green:nth-of-type(2)").text.split(":", 1)[-1].strip(),
                            "Tráº¡ng thÃ¡i": li.find_element(By.CSS_SELECTOR, "div.right > p.red").text.split(":", 1)[-1].strip(),
                            "Ná»™i dung": ""
                        }
                        page_data.append(doc_info)
                    except NoSuchElementException:
                        continue
                        
                main_window = self.driver.current_window_handle
                for doc in page_data:
                    print(f"  ğŸ”— Äang láº¥y ná»™i dung cho: {doc['TÃªn vÄƒn báº£n'][:50]}...")
                    self.driver.switch_to.new_window('tab')
                    self.driver.get(doc["Link chi tiáº¿t"])
                    try:
                        content_div = WebDriverWait(self.driver, 10).until(
                            EC.presence_of_element_located((By.ID, "toanvancontent"))
                        )
                        doc["Ná»™i dung"] = content_div.text
                    except TimeoutException:
                        print(f"  âŒ KhÃ´ng tÃ¬m tháº¥y ná»™i dung cho vÄƒn báº£n nÃ y.")
                    finally:
                        self.driver.close()
                        self.driver.switch_to.window(main_window)

                all_documents.extend(page_data)

                old_ul_element = self.driver.find_element(By.CLASS_NAME, "listLaw")
                next_page_link = self.driver.find_element(By.XPATH, f"//div[@class='paging']//a[text()='{page_number + 1}']")
                next_page_link.click()
                
                WebDriverWait(self.driver, 10).until(EC.staleness_of(old_ul_element))
                page_number += 1

            except NoSuchElementException:
                print("âœ… ÄÃ£ xá»­ lÃ½ háº¿t cÃ¡c trang káº¿t quáº£ cho tá»« khÃ³a nÃ y.")
                break
            except Exception as e:
                print(f"â­• Lá»—i khi xá»­ lÃ½ trang {page_number}: {e}. Dá»«ng láº¡i.")
                break
        
        self.save_to_json(all_documents, keyword, output_dir)

    def save_to_json(self, data: list, keyword: str, output_dir: str):
        """LÆ°u dá»¯ liá»‡u vÃ o file JSON."""
        if not data:
            print("KhÃ´ng cÃ³ dá»¯ liá»‡u Ä‘á»ƒ lÆ°u cho tá»« khÃ³a nÃ y.")
            return

        os.makedirs(output_dir, exist_ok=True)
        
        safe_keyword = "".join(c for c in keyword if c.isalnum() or c in (' ', '_')).rstrip()
        filename = f"metadata_law_{safe_keyword.replace(' ', '_')}.json"
        json_path = os.path.join(output_dir, filename)

        df = pd.DataFrame(data)
        df.to_json(json_path, orient="records", force_ascii=False, indent=4)
        print(f"ğŸ’¾ ÄÃ£ lÆ°u thÃ nh cÃ´ng {len(data)} vÄƒn báº£n vÃ o file: {json_path}")

    def quit(self):
        """ÄÃ³ng trÃ¬nh duyá»‡t."""
        if self.driver:
            self.driver.quit()
            print("\nğŸšª ÄÃ£ Ä‘Ã³ng driver.")

# --- CÃ¡ch sá»­ dá»¥ng class ---
if __name__ == '__main__':
    # --- PHáº¦N Cáº¤U HÃŒNH ---
    # CÃ³ thá»ƒ thÃªm nhiá»u tá»« khÃ³a vÃ o danh sÃ¡ch nÃ y
    KEYWORDS_TO_SEARCH = [
        "giao thÃ´ng Ä‘Æ°á»ng bá»™",
        "an toÃ n thá»±c pháº©m",
        "lao Ä‘á»™ng"
    ]
    
    # Táº¡o má»™t key duy nháº¥t cho má»—i láº§n cháº¡y dá»±a trÃªn thá»i gian
    deploy_key = time.strftime("%Y%m%d-%H%M%S")
    print(f"ğŸ”‘ Deploy key cho láº§n cháº¡y nÃ y: {deploy_key}")
    
    # Táº¡o thÆ° má»¥c output dá»±a trÃªn deploy_key
    BASE_OUTPUT_DIRECTORY = os.path.join("./crawled_data", deploy_key)
    
    # --- PHáº¦N THá»°C THI ---
    ingestion_tool = DataIngestionTool()
    
    try:
        if ingestion_tool.driver:
            # VÃ²ng láº·p Ä‘á»ƒ cÃ o dá»¯ liá»‡u cho tá»«ng tá»« khÃ³a
            for keyword in KEYWORDS_TO_SEARCH:
                ingestion_tool.ingest_data(keyword=keyword, output_dir=BASE_OUTPUT_DIRECTORY)
    finally:
        ingestion_tool.quit()

